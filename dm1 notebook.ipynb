{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b538cc-2a6f-4b61-b1fe-1bba45d274bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /opt/anaconda3/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfc765-45c4-44e7-adfd-48f4ba7409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Amazon and Best Buy datasets\n",
    "amazon_df = pd.read_csv('Amazon transactions.csv')\n",
    "best_buy_df = pd.read_csv('Best Buy transactions.csv')\n",
    "\n",
    "# Load K-Mart, Nike, and Generic datasets\n",
    "kmart_df = pd.read_csv('Kmart transactions.csv')\n",
    "nike_df = pd.read_csv('Nike transactions.csv')\n",
    "generic_df = pd.read_csv('Generic transactions.csv')\n",
    "\n",
    "# Concatenate all datasets\n",
    "all_transactions = pd.concat([amazon_df, best_buy_df, kmart_df, nike_df, generic_df], ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataset to a new CSV file\n",
    "all_transactions.to_csv('All_transactions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1c2bbd-cd32-4912-a1ec-da6e048a6218",
   "metadata": {},
   "source": [
    "# Apriori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf76cbf-3510-4c63-90d7-5aef52ea5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "def preprocess_and_apriori(df, min_support, min_confidence):\n",
    "    # Convert all non-numeric values to strings\n",
    "    df = df.applymap(str)\n",
    "\n",
    "    # Handle NaN values by filling them with an empty string\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "    # Perform Apriori algorithm\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(df.values).transform(df.values)\n",
    "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    # Apriori algorithm\n",
    "    frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "    # Association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "    return frequent_itemsets, rules\n",
    "\n",
    "# Load K-Mart data from CSV file\n",
    "kmart_df = pd.read_csv('Kmart transactions.csv')\n",
    "kmart_min_support = 0.1\n",
    "kmart_min_confidence = 0.7\n",
    "kmart_frequent_itemsets, kmart_rules = preprocess_and_apriori(kmart_df, kmart_min_support, kmart_min_confidence)\n",
    "print(\"\\nK-Mart Frequent Itemsets:\")\n",
    "print(kmart_frequent_itemsets)\n",
    "print(\"\\nK-Mart Association Rules:\")\n",
    "print(kmart_rules)\n",
    "\n",
    "# Load Nike data from CSV file\n",
    "nike_df = pd.read_csv('Nike transactions.csv')\n",
    "nike_min_support = 0.1\n",
    "nike_min_confidence = 0.7\n",
    "nike_frequent_itemsets, nike_rules = preprocess_and_apriori(nike_df, nike_min_support, nike_min_confidence)\n",
    "print(\"\\nNike Frequent Itemsets:\")\n",
    "print(nike_frequent_itemsets)\n",
    "print(\"\\nNike Association Rules:\")\n",
    "print(nike_rules)\n",
    "\n",
    "# Load Generic data from CSV file\n",
    "generic_df = pd.read_csv('Generic transactions.csv')\n",
    "generic_min_support = 0.2\n",
    "generic_min_confidence = 0.7\n",
    "generic_frequent_itemsets, generic_rules = preprocess_and_apriori(generic_df, generic_min_support, generic_min_confidence)\n",
    "print(\"\\nGeneric Frequent Itemsets:\")\n",
    "print(generic_frequent_itemsets)\n",
    "print(\"\\nGeneric Association Rules:\")\n",
    "print(generic_rules)\n",
    "\n",
    "# Load Amazon data from CSV file\n",
    "amazon_df = pd.read_csv('Amazon transactions.csv')\n",
    "amazon_min_support = 0.2\n",
    "amazon_min_confidence = 0.7\n",
    "amazon_frequent_itemsets, amazon_rules = preprocess_and_apriori(amazon_df, amazon_min_support, amazon_min_confidence)\n",
    "print(\"\\nAmazon Frequent Itemsets:\")\n",
    "print(amazon_frequent_itemsets)\n",
    "print(\"\\nAmazon Association Rules:\")\n",
    "print(amazon_rules)\n",
    "\n",
    "# Load Best Buy data from CSV file\n",
    "bestbuy_df = pd.read_csv('Best Buy transactions.csv')\n",
    "bestbuy_min_support = 0.2\n",
    "bestbuy_min_confidence = 0.7\n",
    "bestbuy_frequent_itemsets, bestbuy_rules = preprocess_and_apriori(bestbuy_df, bestbuy_min_support, bestbuy_min_confidence)\n",
    "print(\"\\nBest Buy Frequent Itemsets:\")\n",
    "print(bestbuy_frequent_itemsets)\n",
    "print(\"\\nBest Buy Association Rules:\")\n",
    "print(bestbuy_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbca172-94ae-4bec-b920-238c63903f41",
   "metadata": {},
   "source": [
    "# BRUTE FORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d5a8b-e53b-43a3-ab0a-24aa9153ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Function for the brute-force method\n",
    "def brute_force_frequent_itemsets(transactions, min_support):\n",
    "    itemsets = set()\n",
    "    frequent_itemsets = []\n",
    "\n",
    "    unique_items = set(item for sublist in transactions for item in sublist)\n",
    "\n",
    "    for k in range(1, len(unique_items) + 1):\n",
    "        # Generate all possible k-itemsets\n",
    "        k_itemsets = list(itertools.combinations(unique_items, k))\n",
    "\n",
    "        # Check support for each k-itemset\n",
    "        frequent_k_itemsets = [itemset for itemset in k_itemsets if is_frequent(itemset, transactions, min_support)]\n",
    "\n",
    "        if not frequent_k_itemsets:\n",
    "            break\n",
    "\n",
    "        frequent_itemsets.extend(frequent_k_itemsets)\n",
    "        itemsets.update(frequent_k_itemsets)\n",
    "\n",
    "    return itemsets\n",
    "\n",
    "# Function to check support for an itemset\n",
    "def is_frequent(itemset, transactions, min_support):\n",
    "    support_count = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "    support = support_count / len(transactions)\n",
    "    return support >= min_support\n",
    "\n",
    "# Function to calculate brute force execution time\n",
    "def brute_force_execution_time(transactions, min_support):\n",
    "    start_time = time.time()\n",
    "    brute_force_frequent_itemsets(transactions, min_support)\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Function to calculate Apriori algorithm execution time\n",
    "def apriori_execution_time(transactions, min_support):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    start_time = time.time()\n",
    "    apriori(df, min_support=min_support)\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Function to get frequent itemsets using Apriori algorithm\n",
    "def get_frequent_itemsets(transactions, min_support):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Load other datasets from CSV files\n",
    "amazon_df = pd.read_csv('Amazon transactions.csv')\n",
    "bestbuy_df = pd.read_csv('Best Buy transactions.csv')\n",
    "kmart_df = pd.read_csv('Kmart transactions.csv')\n",
    "nike_df = pd.read_csv('Nike transactions.csv')\n",
    "generic_df = pd.read_csv('Generic transactions.csv')\n",
    "\n",
    "# Convert all non-numeric values to strings\n",
    "amazon_df = amazon_df.applymap(str)\n",
    "bestbuy_df = bestbuy_df.applymap(str)\n",
    "kmart_df = kmart_df.applymap(str)\n",
    "nike_df = nike_df.applymap(str)\n",
    "generic_df = generic_df.applymap(str)\n",
    "\n",
    "# Use Amazon data for brute force method\n",
    "min_support_amazon = 0.2\n",
    "brute_force_time_amazon = brute_force_execution_time(amazon_df.values, min_support_amazon)\n",
    "print(f\"Brute Force Execution Time for Amazon: {brute_force_time_amazon} seconds\")\n",
    "\n",
    "# Use Best Buy data for brute force method\n",
    "min_support_bestbuy = 0.2\n",
    "brute_force_time_bestbuy = brute_force_execution_time(bestbuy_df.values, min_support_bestbuy)\n",
    "print(f\"Brute Force Execution Time for Best Buy: {brute_force_time_bestbuy} seconds\")\n",
    "\n",
    "# Use K-Mart data for brute force method\n",
    "min_support_kmart = 0.2\n",
    "brute_force_time_kmart = brute_force_execution_time(kmart_df.values, min_support_kmart)\n",
    "print(f\"Brute Force Execution Time for K-Mart: {brute_force_time_kmart} seconds\")\n",
    "\n",
    "# Use Nike data for brute force method\n",
    "min_support_nike = 0.2\n",
    "brute_force_time_nike = brute_force_execution_time(nike_df.values, min_support_nike)\n",
    "print(f\"Brute Force Execution Time for Nike: {brute_force_time_nike} seconds\")\n",
    "\n",
    "# Use Generic data for brute force method\n",
    "min_support_generic = 0.2\n",
    "brute_force_time_generic = brute_force_execution_time(generic_df.values, min_support_generic)\n",
    "print(f\"Brute Force Execution Time for Generic: {brute_force_time_generic} seconds\")\n",
    "\n",
    "# Calculate and compare Apriori execution times\n",
    "apriori_time_amazon = apriori_execution_time(amazon_df, 0.2)\n",
    "apriori_time_bestbuy = apriori_execution_time(bestbuy_df, 0.2)\n",
    "apriori_time_kmart = apriori_execution_time(kmart_df, 0.2)\n",
    "apriori_time_nike = apriori_execution_time(nike_df, 0.2)\n",
    "apriori_time_generic = apriori_execution_time(generic_df, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49fbde-0f96-4418-9e2c-c91a4f43dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_execution_time(transactions, min_support):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    start_time = time.time()\n",
    "    apriori(df, min_support=min_support)\n",
    "    return time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af28e8-f518-4189-96d6-f429effdb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_time_amazon = apriori_execution_time(amazon_df.values, 0.2)\n",
    "apriori_time_bestbuy = apriori_execution_time(bestbuy_df.values, 0.2)\n",
    "apriori_time_kmart = apriori_execution_time(kmart_df.values, 0.2)\n",
    "apriori_time_nike = apriori_execution_time(nike_df.values, 0.2)\n",
    "apriori_time_generic = apriori_execution_time(generic_df.values, 0.2)\n",
    "\n",
    "print(f\"Apriori Execution Time for Amazon: {apriori_time_amazon} seconds\")\n",
    "print(f\"Apriori Execution Time for Best Buy: {apriori_time_bestbuy} seconds\")\n",
    "print(f\"Apriori Execution Time for K-Mart: {apriori_time_kmart} seconds\")\n",
    "print(f\"Apriori Execution Time for Nike: {apriori_time_nike} seconds\")\n",
    "print(f\"Apriori Execution Time for Generic: {apriori_time_generic} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
